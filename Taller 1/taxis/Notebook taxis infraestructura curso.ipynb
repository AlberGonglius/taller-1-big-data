{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archivo para intentar correr todo en la infraestructura del curso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cruce espacial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d12d0a13-4793-48fa-9d9a-697bc859f0be",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#dbutils.fs.put(\"/FileStore/my-stuff/my-file.txt\", \"This is the actual text that will be saved to disk. Like a 'Hello world!' example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5583abfc-3651-46c9-ad3c-e906ffa987ea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import year, month, dayofmonth, concat_ws, lpad\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import count, sum\n",
    "import pandas as pd\n",
    "#import seaborn as sns\n",
    "import pyarrow.parquet as pq\n",
    "#import geopandas\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "os.environ[\n",
    "    \"PYSPARK_SUBMIT_ARGS\"\n",
    "] = \"--packages org.apache.hadoop:hadoop-aws:3.2.2,io.delta:delta-core_2.12:1.1.0  pyspark-shell \"\n",
    "config = {\n",
    "    \"spark.jars.packages\":\"org.apache.hadoop:hadoop-aws:3.2.2\",\n",
    "    \"spark.kubernetes.namespace\": \"spark\",\n",
    "    \"spark.kubernetes.container.image\": \"cronosnull/abd-spark-base:202301\",\n",
    "    \"spark.executor.instances\": \"4\",\n",
    "    \"spark.executor.memory\": \"1g\",\n",
    "    \"spark.executor.cores\": \"1\",\n",
    "    \"spark.driver.port\":\"38889\",\n",
    "    \"spark.driver.blockManager.port\":\"7777\",\n",
    "    \"spark.driver.bindAddress\": \"0.0.0.0\",\n",
    "    \"spark.executor.memory\": \"4g\", #4\n",
    "    \"spark.driver.host\":\"172.24.99.30\",\n",
    "    \"spark.kubernetes.executor.request.cores\":\"500m\",\n",
    "    \"spark.hadoop.fs.s3a.endpoint\": \"http://172.24.99.18:9000\",\n",
    "    # Credenciales de MinNIO, no olvide asignar las variables de entorno\n",
    "    \"spark.hadoop.fs.s3a.access.key\": os.environ.get('MINIO_USERNAME', \"--\"),\n",
    "    \"spark.hadoop.fs.s3a.secret.key\": os.environ.get('MINIO_PASSWORD',\"--\"),\n",
    "    \"spark.hadoop.fs.s3a.path.style.access\": True,\n",
    "    \"spark.hadoop.fs.s3a.impl\": \"org.apache.hadoop.fs.s3a.S3AFileSystem\",\n",
    "    \"spark.hadoop.fs.s3a.aws.credentials.provider\": \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\",\n",
    "    \"spark.kubernetes.local.dirs.tmpfs\":True,\n",
    "\n",
    "}\n",
    "def get_spark_session(app_name: str, conf: SparkConf):\n",
    "    conf.setMaster(\"k8s://https://172.24.99.68:16443\")\n",
    "    for key, value in config.items():\n",
    "        conf.set(key, value)    \n",
    "    return SparkSession.builder.appName(app_name).config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8313c54d-d1fd-4297-bad4-a07fe4691e42",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark = get_spark_session(\"grupo03-taxis\", SparkConf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\r\n",
      "      ____              __\r\n",
      "     / __/__  ___ _____/ /__\r\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\r\n",
      "   /___/ .__/\\_,_/_/ /_/\\_\\   version 3.2.0\r\n",
      "      /_/\r\n",
      "                        \r\n",
      "Using Scala version 2.12.15, OpenJDK 64-Bit Server VM, 1.8.0_322\r\n",
      "Branch \r\n",
      "Compiled by user  on 2022-03-26T09:34:47Z\r\n",
      "Revision \r\n",
      "Url \r\n",
      "Type --help for more information.\r\n"
     ]
    }
   ],
   "source": [
    "!spark-submit --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.24.99.30:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>k8s://https://172.24.99.68:16443</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>grupo03-taxis</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f150af54df0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                 Version    \n",
      "----------------------- -----------\n",
      "anyio                   3.5.0      \n",
      "argon2-cffi             21.3.0     \n",
      "argon2-cffi-bindings    21.2.0     \n",
      "attrs                   22.1.0     \n",
      "backcall                0.2.0      \n",
      "beautifulsoup4          4.11.1     \n",
      "bitarray                2.5.1      \n",
      "bleach                  4.1.0      \n",
      "branca                  0.6.0      \n",
      "brotlipy                0.7.0      \n",
      "certifi                 2023.7.22  \n",
      "cffi                    1.14.5     \n",
      "charset-normalizer      2.0.4      \n",
      "click                   8.0.4      \n",
      "click-plugins           1.1.1      \n",
      "cligj                   0.7.2      \n",
      "conda                   23.1.0     \n",
      "conda-package-handling  2.0.2      \n",
      "conda-package-streaming 0.7.0      \n",
      "contourpy               1.0.5      \n",
      "cryptography            38.0.4     \n",
      "cycler                  0.11.0     \n",
      "decorator               5.1.1      \n",
      "defusedxml              0.7.1      \n",
      "entrypoints             0.4        \n",
      "fastjsonschema          2.16.2     \n",
      "Fiona                   1.8.22     \n",
      "flit-core               3.6.0      \n",
      "folium                  0.14.0     \n",
      "fonttools               4.25.0     \n",
      "future                  0.18.2     \n",
      "GDAL                    3.0.2      \n",
      "geopandas               0.12.2     \n",
      "idna                    3.4        \n",
      "importlib-resources     5.2.0      \n",
      "ipykernel               5.3.4      \n",
      "ipython                 7.22.0     \n",
      "ipython-genutils        0.2.0      \n",
      "jedi                    0.17.0     \n",
      "Jinja2                  3.1.2      \n",
      "joblib                  1.2.0      \n",
      "jsonschema              4.16.0     \n",
      "jupyter-client          6.1.12     \n",
      "jupyter-core            5.1.1      \n",
      "jupyter-server          1.23.4     \n",
      "jupyterlab-pygments     0.1.2      \n",
      "kiwisolver              1.4.4      \n",
      "lxml                    4.9.1      \n",
      "mapclassify             2.5.0      \n",
      "MarkupSafe              2.1.1      \n",
      "matplotlib              3.7.2      \n",
      "mistune                 0.8.4      \n",
      "mkl-fft                 1.3.1      \n",
      "mkl-random              1.2.2      \n",
      "mkl-service             2.4.0      \n",
      "munch                   2.5.0      \n",
      "munkres                 1.1.4      \n",
      "nbclassic               0.4.8      \n",
      "nbclient                0.5.13     \n",
      "nbconvert               6.5.4      \n",
      "nbformat                5.7.0      \n",
      "nest-asyncio            1.5.6      \n",
      "networkx                3.1        \n",
      "notebook                6.5.2      \n",
      "notebook-shim           0.2.2      \n",
      "numpy                   1.23.5     \n",
      "packaging               22.0       \n",
      "pandas                  1.2.4      \n",
      "pandocfilters           1.5.0      \n",
      "parso                   0.8.3      \n",
      "pexpect                 4.8.0      \n",
      "pickleshare             0.7.5      \n",
      "Pillow                  9.4.0      \n",
      "pip                     18.1       \n",
      "pkgutil-resolve-name    1.3.10     \n",
      "platformdirs            2.5.2      \n",
      "pluggy                  1.0.0      \n",
      "pooch                   1.7.0      \n",
      "prometheus-client       0.14.1     \n",
      "prompt-toolkit          3.0.36     \n",
      "ptyprocess              0.7.0      \n",
      "py4j                    0.10.9.2   \n",
      "pyarrow                 3.0.0      \n",
      "pycosat                 0.6.4      \n",
      "pycparser               2.21       \n",
      "pycrypto                2.6.1      \n",
      "Pygments                2.11.2     \n",
      "pyOpenSSL               22.0.0     \n",
      "pyparsing               3.0.9      \n",
      "pyproj                  2.6.1.post1\n",
      "pyrsistent              0.18.0     \n",
      "PySocks                 1.7.1      \n",
      "pyspark                 3.2.0      \n",
      "python-dateutil         2.8.2      \n",
      "pytz                    2022.7     \n",
      "pyzmq                   23.2.0     \n",
      "requests                2.28.1     \n",
      "Rtree                   1.0.1      \n",
      "ruamel.yaml             0.17.21    \n",
      "ruamel.yaml.clib        0.2.6      \n",
      "scikit-learn            1.3.0      \n",
      "scipy                   1.10.1     \n",
      "seaborn                 0.12.2     \n",
      "Send2Trash              1.8.0      \n",
      "setuptools              65.6.3     \n",
      "Shapely                 1.8.4      \n",
      "six                     1.16.0     \n",
      "sniffio                 1.2.0      \n",
      "soupsieve               2.3.2.post1\n",
      "terminado               0.17.1     \n",
      "threadpoolctl           2.2.0      \n",
      "tinycss2                1.2.1      \n",
      "toolz                   0.12.0     \n",
      "tornado                 6.2        \n",
      "tqdm                    4.64.1     \n",
      "traitlets               5.7.1      \n",
      "typing-extensions       4.4.0      \n",
      "urllib3                 1.26.14    \n",
      "wcwidth                 0.2.5      \n",
      "webencodings            0.5.1      \n",
      "websocket-client        0.58.0     \n",
      "wheel                   0.37.1     \n",
      "xyzservices             2022.9.0   \n",
      "zipp                    3.11.0     \n",
      "zstandard               0.18.0     \n",
      "\u001b[33mYou are using pip version 18.1, however version 23.2.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "401fa81c-1661-4a66-922a-73e90809589e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests \n",
    "import geopandas as gpd #geopandas 0.9\n",
    "#import pygeos #0.8\n",
    "#gpd.options.use_pygeos = True\n",
    "\n",
    "\n",
    "request = requests.get('https://raw.githubusercontent.com/AlberGonglius/taller-1-big-data/main/NYCTaxiZones.json')\n",
    "geojson = request.json()\n",
    "zone_gdf = gpd.GeoDataFrame.from_features(geojson['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85c7e609-ab75-46f0-aac8-2fda0608e157",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Función para el geojoin \n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import col, pandas_udf\n",
    "\n",
    "def create_sjoin_udf(gdf_with_poly,join_column_name):\n",
    "    def sjoin_settlement(x, y):\n",
    "        gdf_temp = gpd.GeoDataFrame(data = [[x] for x in range(len(x))],geometry=gpd.points_from_xy(x,y),columns=['id'])\n",
    "        settlement = gpd.sjoin(gdf_temp,gdf_with_poly[['borough','geometry']],how='left')#.fillna(np.nan)\n",
    "        \n",
    "        return settlement.groupby('id').agg({'borough':lambda x: list(x)}).reset_index().sort_values(by='id').loc[:,join_column_name].astype('str').str.strip('[]').str.strip(\"'\")# if pd.isnull(sum(x)) == False else np.nan}).reset_index().sort_values(by='id').loc[:,join_column_name]\n",
    "    return pandas_udf(sjoin_settlement, returnType=StringType())\n",
    "sjoin_udf = create_sjoin_udf(zone_gdf,'borough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19572063-11d0-44b1-8556-c27e1b8ab59b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>shape_area</th>\n",
       "      <th>objectid</th>\n",
       "      <th>shape_leng</th>\n",
       "      <th>location_id</th>\n",
       "      <th>zone</th>\n",
       "      <th>borough</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MULTIPOLYGON (((-74.18445 40.69500, -74.18449 ...</td>\n",
       "      <td>0.0007823067885</td>\n",
       "      <td>1</td>\n",
       "      <td>0.116357453189</td>\n",
       "      <td>1</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>EWR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MULTIPOLYGON (((-73.82338 40.63899, -73.82277 ...</td>\n",
       "      <td>0.00486634037837</td>\n",
       "      <td>2</td>\n",
       "      <td>0.43346966679</td>\n",
       "      <td>2</td>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>Queens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MULTIPOLYGON (((-73.84793 40.87134, -73.84725 ...</td>\n",
       "      <td>0.000314414156821</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0843411059012</td>\n",
       "      <td>3</td>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>Bronx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MULTIPOLYGON (((-73.97177 40.72582, -73.97179 ...</td>\n",
       "      <td>0.000111871946192</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0435665270921</td>\n",
       "      <td>4</td>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MULTIPOLYGON (((-74.17422 40.56257, -74.17349 ...</td>\n",
       "      <td>0.000497957489363</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0921464898574</td>\n",
       "      <td>5</td>\n",
       "      <td>Arden Heights</td>\n",
       "      <td>Staten Island</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>MULTIPOLYGON (((-73.95834 40.71331, -73.95681 ...</td>\n",
       "      <td>0.000168611097013</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0679149669603</td>\n",
       "      <td>256</td>\n",
       "      <td>Williamsburg (South Side)</td>\n",
       "      <td>Brooklyn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>MULTIPOLYGON (((-73.85107 40.91037, -73.85207 ...</td>\n",
       "      <td>0.000394552487366</td>\n",
       "      <td>259</td>\n",
       "      <td>0.126750305191</td>\n",
       "      <td>259</td>\n",
       "      <td>Woodlawn/Wakefield</td>\n",
       "      <td>Bronx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>MULTIPOLYGON (((-73.90175 40.76078, -73.90147 ...</td>\n",
       "      <td>0.000422345326907</td>\n",
       "      <td>260</td>\n",
       "      <td>0.133514154636</td>\n",
       "      <td>260</td>\n",
       "      <td>Woodside</td>\n",
       "      <td>Queens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>MULTIPOLYGON (((-74.01333 40.70503, -74.01327 ...</td>\n",
       "      <td>0.0000343423231652</td>\n",
       "      <td>261</td>\n",
       "      <td>0.0271204563616</td>\n",
       "      <td>261</td>\n",
       "      <td>World Trade Center</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>MULTIPOLYGON (((-73.94383 40.78286, -73.94376 ...</td>\n",
       "      <td>0.000122330270966</td>\n",
       "      <td>262</td>\n",
       "      <td>0.0490636231541</td>\n",
       "      <td>262</td>\n",
       "      <td>Yorkville East</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>263 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              geometry          shape_area  \\\n",
       "0    MULTIPOLYGON (((-74.18445 40.69500, -74.18449 ...     0.0007823067885   \n",
       "1    MULTIPOLYGON (((-73.82338 40.63899, -73.82277 ...    0.00486634037837   \n",
       "2    MULTIPOLYGON (((-73.84793 40.87134, -73.84725 ...   0.000314414156821   \n",
       "3    MULTIPOLYGON (((-73.97177 40.72582, -73.97179 ...   0.000111871946192   \n",
       "4    MULTIPOLYGON (((-74.17422 40.56257, -74.17349 ...   0.000497957489363   \n",
       "..                                                 ...                 ...   \n",
       "258  MULTIPOLYGON (((-73.95834 40.71331, -73.95681 ...   0.000168611097013   \n",
       "259  MULTIPOLYGON (((-73.85107 40.91037, -73.85207 ...   0.000394552487366   \n",
       "260  MULTIPOLYGON (((-73.90175 40.76078, -73.90147 ...   0.000422345326907   \n",
       "261  MULTIPOLYGON (((-74.01333 40.70503, -74.01327 ...  0.0000343423231652   \n",
       "262  MULTIPOLYGON (((-73.94383 40.78286, -73.94376 ...   0.000122330270966   \n",
       "\n",
       "    objectid       shape_leng location_id                       zone  \\\n",
       "0          1   0.116357453189           1             Newark Airport   \n",
       "1          2    0.43346966679           2                Jamaica Bay   \n",
       "2          3  0.0843411059012           3    Allerton/Pelham Gardens   \n",
       "3          4  0.0435665270921           4              Alphabet City   \n",
       "4          5  0.0921464898574           5              Arden Heights   \n",
       "..       ...              ...         ...                        ...   \n",
       "258      256  0.0679149669603         256  Williamsburg (South Side)   \n",
       "259      259   0.126750305191         259         Woodlawn/Wakefield   \n",
       "260      260   0.133514154636         260                   Woodside   \n",
       "261      261  0.0271204563616         261         World Trade Center   \n",
       "262      262  0.0490636231541         262             Yorkville East   \n",
       "\n",
       "           borough  \n",
       "0              EWR  \n",
       "1           Queens  \n",
       "2            Bronx  \n",
       "3        Manhattan  \n",
       "4    Staten Island  \n",
       "..             ...  \n",
       "258       Brooklyn  \n",
       "259          Bronx  \n",
       "260         Queens  \n",
       "261      Manhattan  \n",
       "262      Manhattan  \n",
       "\n",
       "[263 rows x 7 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zone_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "907ab263-7cdd-4211-99b2-5ac0297052af",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+------------------+---------------+------------------+----------------+-----------------+\n",
      "|    pickup_datetime|     trip_distance|  pickup_longitude|pickup_latitude| dropoff_longitude|dropoff_latitude|     total_amount|\n",
      "+-------------------+------------------+------------------+---------------+------------------+----------------+-----------------+\n",
      "|2010-01-26 07:41:00|              0.75|        -73.956778|       40.76775|        -73.965957|       40.765232|              5.0|\n",
      "|2010-01-30 23:31:00|               5.9|-73.99611799999998|      40.763932|-73.98151199999998|       40.741193|             16.3|\n",
      "|2010-01-18 20:22:20|               4.0|        -73.979673|       40.78379|-73.91785199999998|        40.87856|             12.7|\n",
      "|2010-01-09 01:18:00|               4.7|        -73.977922|      40.763997|-73.92390799999998|       40.759725|             14.3|\n",
      "|2010-01-18 19:10:14|0.5999999999999999|        -73.990924|      40.734682|-73.99551099999998|       40.739088|             6.67|\n",
      "|2010-01-23 18:40:25|               3.3|               0.0|            0.0|               0.0|             0.0|             12.0|\n",
      "|2010-01-17 09:18:00|              1.33|        -73.993747|      40.754917|-73.98471499999998|       40.755927|              6.6|\n",
      "|2010-01-09 13:49:00|              1.83|         -73.97103|      40.751307|         -73.99056|       40.734923|              7.4|\n",
      "|2010-01-09 00:25:00|              3.28|        -73.990037|      40.725633|        -73.993842|       40.761697|             12.3|\n",
      "|2010-01-27 18:15:00|              1.42|        -73.979623|       40.74378|-73.98941499999998|       40.756788|             12.0|\n",
      "|2010-01-08 16:05:00|0.8399999999999999|        -74.000917|       40.75728|        -73.989767|       40.757407|             10.2|\n",
      "|2010-01-09 02:07:00|              2.76|        -73.991175|      40.728072|        -73.979307|        40.74422|             11.1|\n",
      "|2010-01-16 19:04:00|              1.52|        -73.980985|      40.737848|-74.00325499999998|       40.738717|             11.0|\n",
      "|2010-01-08 17:15:00|              7.12|-73.84416799999998|      40.721353|        -73.931442|       40.670685|             21.2|\n",
      "|2010-01-14 19:23:15|               1.4|        -73.955577|      40.772523|-73.99111999999998|       40.755463|             11.2|\n",
      "|2010-01-06 22:34:49|               1.1|        -74.010253|       40.72055|-74.00396499999998|       40.715782|              6.7|\n",
      "|2010-01-20 15:52:26|               2.0|-73.96953499999998|      40.800547|        -73.942722|       40.841573|             10.5|\n",
      "|2010-01-22 11:54:52|               1.1|        -73.996835|      40.716547|-73.94853999999998|        40.79509|              5.4|\n",
      "|2010-01-26 16:59:00|              1.34|-73.98881299999998|      40.736657|        -73.980332|       40.723988|7.599999999999999|\n",
      "|2010-01-26 12:05:00|              1.64|-73.99038799999998|       40.74583|        -74.007802|       40.745153|             11.2|\n",
      "+-------------------+------------------+------------------+---------------+------------------+----------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#se leen los primeros parquet que se saben tienen la misma esrtuctura y solo las cols que importan\n",
    "#2010 cambia los nombres de las columnas a 'pickup_datetime', 'trip_distance',  'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude','total_amount'\n",
    "#2009 ya está\n",
    "df1 = spark.read.parquet(\"s3a://taxis/parquet/yellow_tripdata_2010-01.parquet\").select('pickup_datetime', 'trip_distance',  'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude','total_amount')\n",
    "df2 = spark.read.parquet(\"s3a://taxis/parquet/yellow_tripdata_2010-02.parquet\").select('pickup_datetime', 'trip_distance',  'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude','total_amount')\n",
    "df3 = spark.read.parquet(\"s3a://taxis/parquet/yellow_tripdata_2010-03.parquet\").select('pickup_datetime', 'trip_distance',  'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude','total_amount')\n",
    "df4 = spark.read.parquet(\"s3a://taxis/parquet/yellow_tripdata_2010-04.parquet\").select('pickup_datetime', 'trip_distance',  'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude','total_amount')\n",
    "df5 = spark.read.parquet(\"s3a://taxis/parquet/yellow_tripdata_2010-05.parquet\").select('pickup_datetime', 'trip_distance',  'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude','total_amount')\n",
    "df6 = spark.read.parquet(\"s3a://taxis/parquet/yellow_tripdata_2010-06.parquet\").select('pickup_datetime', 'trip_distance',  'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude','total_amount')\n",
    "df7 = spark.read.parquet(\"s3a://taxis/parquet/yellow_tripdata_2010-07.parquet\").select('pickup_datetime', 'trip_distance',  'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude','total_amount')\n",
    "df8 = spark.read.parquet(\"s3a://taxis/parquet/yellow_tripdata_2010-08.parquet\").select('pickup_datetime', 'trip_distance',  'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude','total_amount')\n",
    "df9 = spark.read.parquet(\"s3a://taxis/parquet/yellow_tripdata_2010-09.parquet\").select('pickup_datetime', 'trip_distance',  'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude','total_amount')\n",
    "df10 = spark.read.parquet(\"s3a://taxis/parquet/yellow_tripdata_2010-10.parquet\").select('pickup_datetime', 'trip_distance',  'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude','total_amount')\n",
    "df11 = spark.read.parquet(\"s3a://taxis/parquet/yellow_tripdata_2010-11.parquet\").select('pickup_datetime', 'trip_distance',  'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude','total_amount')\n",
    "df12 = spark.read.parquet(\"s3a://taxis/parquet/yellow_tripdata_2010-12.parquet\").select('pickup_datetime', 'trip_distance',  'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude','total_amount')\n",
    "\n",
    "df = df1.union(df2).union(df3).union(df4).union(df5).union(df6).union(df7).union(df8).union(df9).union(df10).union(df11).union(df12)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pu_lon ='pickup_longitude'\n",
    "pu_lat = 'pickup_latitude'\n",
    "do_lon ='dropoff_longitude'\n",
    "do_lat = 'dropoff_latitude'\n",
    "dat = 'pickup_datetime'\n",
    "amt = 'total_amount'\n",
    "dist = 'trip_distance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c45f378-240a-4345-842b-5c39912a6a8e",
     "showTitle": false,
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "PythonException",
     "evalue": "\n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"<ipython-input-28-f6d58a01fa7a>\", line 8, in sjoin_settlement\n  File \"/opt/conda/lib/python3.8/site-packages/geopandas/tools/sjoin.py\", line 124, in sjoin\n    indices = _geom_predicate_query(left_df, right_df, predicate)\n  File \"/opt/conda/lib/python3.8/site-packages/geopandas/tools/sjoin.py\", line 217, in _geom_predicate_query\n    input_geoms = left_df.geometry\n  File \"/opt/conda/lib/python3.8/site-packages/geopandas/base.py\", line 2788, in sindex\n    return self.geometry.values.sindex\n  File \"/opt/conda/lib/python3.8/site-packages/geopandas/array.py\", line 295, in sindex\n    self._sindex = _get_sindex_class()(self.data)\n  File \"/opt/conda/lib/python3.8/site-packages/geopandas/sindex.py\", line 21, in _get_sindex_class\n    raise ImportError(\nImportError: Spatial indexes require either `rtree` or `pygeos`. See installation instructions at https://geopandas.org/install.html\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPythonException\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-d22b947e190b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PU_zone'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msjoin_udf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpickup_longitude\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpickup_latitude\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DO_zone'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msjoin_udf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropoff_longitude\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropoff_latitude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1309\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1310\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPythonException\u001b[0m: \n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"<ipython-input-28-f6d58a01fa7a>\", line 8, in sjoin_settlement\n  File \"/opt/conda/lib/python3.8/site-packages/geopandas/tools/sjoin.py\", line 124, in sjoin\n    indices = _geom_predicate_query(left_df, right_df, predicate)\n  File \"/opt/conda/lib/python3.8/site-packages/geopandas/tools/sjoin.py\", line 217, in _geom_predicate_query\n    input_geoms = left_df.geometry\n  File \"/opt/conda/lib/python3.8/site-packages/geopandas/base.py\", line 2788, in sindex\n    return self.geometry.values.sindex\n  File \"/opt/conda/lib/python3.8/site-packages/geopandas/array.py\", line 295, in sindex\n    self._sindex = _get_sindex_class()(self.data)\n  File \"/opt/conda/lib/python3.8/site-packages/geopandas/sindex.py\", line 21, in _get_sindex_class\n    raise ImportError(\nImportError: Spatial indexes require either `rtree` or `pygeos`. See installation instructions at https://geopandas.org/install.html\n"
     ]
    }
   ],
   "source": [
    "#df_subset = df.limit(50)\n",
    "#zonas de recogida y dejada\n",
    "df = df.withColumn('PU_zone',sjoin_udf(df.pickup_longitude,df.pickup_latitude ))\n",
    "df = df.withColumn('DO_zone',sjoin_udf(df.dropoff_longitude,df.dropoff_latitude))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este error no fue posible solucionarlo ni instalando una imágen personalizadacon los paquetes preinstalados. En el listado se observa que rtree si está instalado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b4ee595-3d8d-4f38-9f1f-4bc46b0024e7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#crea la col \"pickup_date\" que contiene el año-mes-dia de \"tpep_pickup_datetime\"\n",
    "\n",
    "#se necesita independientemente cada una...\n",
    "df = df.withColumn(\"pickup_year\", year(df[dat]))\n",
    "df = df.withColumn(\"pickup_month\", month(df[dat]))\n",
    "#df = df.withColumn(\"pickup_day\", dayofmonth(df[dat]))\n",
    "\n",
    "\n",
    "# Muestra el DataFrame resultante con la nueva columna\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34d9f73d-ea00-4fde-b948-0c9c42c673d3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Repartición para ver si mejora desempeño\n",
    "#df = df.repartition(30, 'pickup_day')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7caf9e0-751b-45e1-bb69-aae4405775a7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def _map_to_pandas(rdds):\n",
    "    \"\"\" Needs to be here due to pickling issues \"\"\"\n",
    "    return [pd.DataFrame(list(rdds))]\n",
    "\n",
    "\n",
    "def toPandas2(df, n_partitions=None):\n",
    "    \"\"\"\n",
    "    Returns the contents of `df` as a local `pandas.DataFrame` in a speedy fashion. The DataFrame is\n",
    "    repartitioned if `n_partitions` is passed.\n",
    "    :param df:              pyspark.sql.DataFrame\n",
    "    :param n_partitions:    int or None\n",
    "    :return:                pandas.DataFrame\n",
    "    \"\"\"\n",
    "    if n_partitions is not None: df = df.repartition(n_partitions)\n",
    "    df_pand = df.rdd.mapPartitions(_map_to_pandas).collect()\n",
    "    df_pand = pd.concat(df_pand)\n",
    "    df_pand.columns = df.columns\n",
    "    return df_pand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e535f18e-154c-4b82-9bfc-64828cd0418e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count, sum\n",
    "\n",
    "agg_df = df.groupBy(\"pickup_year\", \"pickup_month\", \"PU_zone\", \"DO_zone\" ).agg(count(\"*\").alias(\"conteo\"), sum(\"Total_Amt\").alias(\"tot_amt\"), sum(\"Trip_Distance\").alias(\"distancia\"))\n",
    "\n",
    "#si quisiera redondear:\n",
    "#agg_df = agg_df.withColumn(\"tot_amt\", round(agg_df[\"tot_amt\"], 2))\n",
    "\n",
    "\n",
    "# Muestra el nuevo DataFrame\n",
    "#agg_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cef2ff7e-f53b-4013-830e-81329aa1e1e8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "a= agg_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "116e6be4-2a6d-4bee-b336-12c68dbf974f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cruce de los demás archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista para sacar 2011 a 2016. Para generar el resto cambiar el rango a range(2017,2023)\n",
    "#Se realiza de esta manera porque no fue posible generar el archivo agregado sobre todo el dataset y se particionó de esta manera.\n",
    "lista = []\n",
    "\n",
    "for i in range(2011,2017):\n",
    "    if i <2016:\n",
    "        for j in range(1,13):\n",
    "            if j < 10:\n",
    "                lista.append(\"s3a://taxis/parquet/yellow_tripdata_\"+str(i)+\"-0\"+str(j)+\".parquet\")\n",
    "            else:\n",
    "                lista.append(\"s3a://taxis/parquet/yellow_tripdata_\"+str(i)+\"-\"+str(j)+\".parquet\")\n",
    "    else:\n",
    "        for j in range(1,12):\n",
    "            if j < 10:\n",
    "                lista.append(\"s3a://taxis/parquet/yellow_tripdata_\"+str(i)+\"-0\"+str(j)+\".parquet\")\n",
    "            else:\n",
    "                lista.append(\"s3a://taxis/parquet/yellow_tripdata_\"+str(i)+\"-\"+str(j)+\".parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s3a://taxis/parquet/yellow_tripdata_2011-01.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2011-02.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2011-03.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2011-04.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2011-05.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2011-06.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2011-07.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2011-08.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2011-09.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2011-10.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2011-11.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2011-12.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2012-01.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2012-02.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2012-03.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2012-04.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2012-05.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2012-06.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2012-07.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2012-08.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2012-09.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2012-10.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2012-11.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2012-12.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2013-01.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2013-02.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2013-03.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2013-04.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2013-05.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2013-06.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2013-07.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2013-08.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2013-09.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2013-10.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2013-11.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2013-12.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2014-01.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2014-02.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2014-03.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2014-04.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2014-05.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2014-06.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2014-07.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2014-08.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2014-09.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2014-10.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2014-11.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2014-12.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2015-01.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2015-02.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2015-03.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2015-04.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2015-05.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2015-06.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2015-07.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2015-08.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2015-09.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2015-10.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2015-11.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2015-12.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2016-01.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2016-02.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2016-03.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2016-04.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2016-05.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2016-06.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2016-07.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2016-08.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2016-09.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2016-10.parquet',\n",
       " 's3a://taxis/parquet/yellow_tripdata_2016-11.parquet']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+------------+------------+------------+\n",
      "|tpep_pickup_datetime|trip_distance|PULocationID|DOLocationID|total_amount|\n",
      "+--------------------+-------------+------------+------------+------------+\n",
      "| 2016-12-01 00:26:26|          0.0|         145|         145|         3.8|\n",
      "| 2016-12-01 00:08:13|          4.2|         262|         226|        16.8|\n",
      "| 2016-12-01 00:36:29|          1.1|         238|          75|         6.8|\n",
      "| 2016-12-01 00:55:28|          1.2|         237|         230|         7.8|\n",
      "| 2016-12-01 00:13:08|         1.48|         142|         161|       15.38|\n",
      "| 2016-12-01 00:43:16|         2.25|         142|         262|       12.88|\n",
      "| 2016-12-01 00:27:18|          3.4|         234|         236|        14.8|\n",
      "| 2016-12-01 00:35:50|          0.7|         237|         237|        6.95|\n",
      "| 2016-12-01 00:19:45|          2.2|         162|         107|        10.3|\n",
      "| 2016-12-01 00:36:40|          1.2|         114|          79|         8.3|\n",
      "| 2016-12-01 00:12:55|          1.9|         142|          68|        10.3|\n",
      "| 2016-12-01 00:17:22|          1.1|         231|         249|        8.15|\n",
      "| 2016-12-01 00:30:08|          1.2|         114|          79|        9.95|\n",
      "| 2016-12-01 00:40:18|          7.8|         138|          75|       41.04|\n",
      "| 2016-12-01 00:04:56|          3.6|         230|         151|       19.75|\n",
      "| 2016-12-01 00:36:44|          0.8|         239|         239|         7.3|\n",
      "| 2016-12-01 00:01:18|          2.3|         113|          88|        11.3|\n",
      "| 2016-12-01 00:04:35|          0.8|         161|         141|        8.75|\n",
      "| 2016-12-01 00:21:00|          3.7|         100|         232|       20.15|\n",
      "| 2016-12-01 00:18:05|        21.73|         132|         244|       70.01|\n",
      "+--------------------+-------------+------------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"s3a://taxis/parquet/yellow_tripdata_2016-12.parquet\").select('tpep_pickup_datetime', 'trip_distance',  'PULocationID', 'DOLocationID','total_amount')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_path in lista:\n",
    "    df1 = spark.read.parquet(file_path).select('tpep_pickup_datetime', 'trip_distance',  'PULocationID', 'DOLocationID','total_amount')\n",
    "    df=df.union(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"pickup_year\", year(df[\"tpep_pickup_datetime\"]))\n",
    "df = df.withColumn(\"pickup_month\", month(df[\"tpep_pickup_datetime\"]))\n",
    "#df = df.withColumn(\"pickup_day\", dayofmonth(df[\"tpep_pickup_datetime\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_zone =  spark.read.csv(\"s3a://taxis/taxi_zone_lookup.csv\", header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_zone = taxi_zone.withColumn(\"LocationId\", col(\"LocationId\").cast(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[LocationId: int, Borough: string, Zone: string, service_zone: string]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+------------+------------+------------+-----------+------------+--------------------+--------------------+\n",
      "|tpep_pickup_datetime|trip_distance|PULocationID|DOLocationID|total_amount|pickup_year|pickup_month|             PU_Zone|             DO_Zone|\n",
      "+--------------------+-------------+------------+------------+------------+-----------+------------+--------------------+--------------------+\n",
      "| 2016-12-01 00:26:26|          0.0|         145|         145|         3.8|       2016|          12|Long Island City/...|Long Island City/...|\n",
      "| 2016-12-01 00:08:13|          4.2|         262|         226|        16.8|       2016|          12|      Yorkville East|           Sunnyside|\n",
      "| 2016-12-01 00:36:29|          1.1|         238|          75|         6.8|       2016|          12|Upper West Side N...|   East Harlem South|\n",
      "| 2016-12-01 00:55:28|          1.2|         237|         230|         7.8|       2016|          12|Upper East Side S...|Times Sq/Theatre ...|\n",
      "| 2016-12-01 00:13:08|         1.48|         142|         161|       15.38|       2016|          12| Lincoln Square East|      Midtown Center|\n",
      "| 2016-12-01 00:43:16|         2.25|         142|         262|       12.88|       2016|          12| Lincoln Square East|      Yorkville East|\n",
      "| 2016-12-01 00:27:18|          3.4|         234|         236|        14.8|       2016|          12|            Union Sq|Upper East Side N...|\n",
      "| 2016-12-01 00:35:50|          0.7|         237|         237|        6.95|       2016|          12|Upper East Side S...|Upper East Side S...|\n",
      "| 2016-12-01 00:19:45|          2.2|         162|         107|        10.3|       2016|          12|        Midtown East|            Gramercy|\n",
      "| 2016-12-01 00:36:40|          1.2|         114|          79|         8.3|       2016|          12|Greenwich Village...|        East Village|\n",
      "| 2016-12-01 00:12:55|          1.9|         142|          68|        10.3|       2016|          12| Lincoln Square East|        East Chelsea|\n",
      "| 2016-12-01 00:17:22|          1.1|         231|         249|        8.15|       2016|          12|TriBeCa/Civic Center|        West Village|\n",
      "| 2016-12-01 00:30:08|          1.2|         114|          79|        9.95|       2016|          12|Greenwich Village...|        East Village|\n",
      "| 2016-12-01 00:40:18|          7.8|         138|          75|       41.04|       2016|          12|   LaGuardia Airport|   East Harlem South|\n",
      "| 2016-12-01 00:04:56|          3.6|         230|         151|       19.75|       2016|          12|Times Sq/Theatre ...|    Manhattan Valley|\n",
      "| 2016-12-01 00:36:44|          0.8|         239|         239|         7.3|       2016|          12|Upper West Side S...|Upper West Side S...|\n",
      "| 2016-12-01 00:01:18|          2.3|         113|          88|        11.3|       2016|          12|Greenwich Village...|Financial Distric...|\n",
      "| 2016-12-01 00:04:35|          0.8|         161|         141|        8.75|       2016|          12|      Midtown Center|     Lenox Hill West|\n",
      "| 2016-12-01 00:21:00|          3.7|         100|         232|       20.15|       2016|          12|    Garment District|Two Bridges/Sewar...|\n",
      "| 2016-12-01 00:18:05|        21.73|         132|         244|       70.01|       2016|          12|         JFK Airport|Washington Height...|\n",
      "+--------------------+-------------+------------+------------+------------+-----------+------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Selecciona las columnas de df2 que deseas agregar\n",
    "#Zona\n",
    "#col_zones = taxi_zone.select(\"LocationId\", \"Zone\")\n",
    "#zona de servicio\n",
    "zone = 'Zone'\n",
    "col_zones = taxi_zone.select(\"LocationId\", zone)\n",
    "\n",
    "# Agrega las columnas de PU al DataFrame original\n",
    "df = df.join(col_zones, df.PULocationID == col_zones.LocationId, how=\"left\")\n",
    "df = df.withColumnRenamed(zone, \"PU_Zone\")\n",
    "#elimina la columna LocationId porque ya no se necesita\n",
    "df = df.drop(\"LocationId\")\n",
    "#se hace lo mismo para el punto de llegada\n",
    "df = df.join(col_zones, df.DOLocationID == col_zones.LocationId, how=\"left\")\n",
    "df = df.withColumnRenamed(zone, \"DO_Zone\")\n",
    "#elimina la columna LocationId porque ya no se necesita\n",
    "df = df.drop(\"LocationId\")\n",
    "\n",
    "# Muestra el resultado\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+--------------------+--------------------+------+------------------+------------------+\n",
      "|pickup_year|pickup_month|             PU_Zone|             DO_Zone|conteo|           tot_amt|         distancia|\n",
      "+-----------+------------+--------------------+--------------------+------+------------------+------------------+\n",
      "|       2011|           1|         Murray Hill| Lincoln Square East|  6747| 78132.66999999972|16231.510000000066|\n",
      "|       2011|           1|Upper West Side S...|Upper West Side N...| 30904|183989.21000000418|26444.189999999875|\n",
      "|       2011|           1|      Yorkville West|Upper East Side N...| 19302|111438.52000000021|13589.480000000087|\n",
      "|       2011|           1|Penn Station/Madi...|      Midtown Center| 25421| 203175.0099999982|33611.819999999985|\n",
      "|       2011|           1|Greenwich Village...|        Bloomingdale|   338|           7038.62|2179.1599999999985|\n",
      "|       2011|           1|   Battery Park City|         Boerum Hill|   166| 2468.719999999999| 694.0199999999996|\n",
      "|       2011|           1| UN/Turtle Bay South|        East Chelsea|  2783| 31066.93999999995| 5943.049999999995|\n",
      "|       2011|           1|            Union Sq| Little Italy/NoLiTa|  7516| 67908.97999999998|11942.229999999947|\n",
      "|       2011|           1|   LaGuardia Airport|      Yorkville East|  2669| 75387.97000000002|          21719.05|\n",
      "|       2011|           1|Greenwich Village...|      Midtown Center|  4614| 52207.60999999987|          12227.79|\n",
      "|       2011|           1|   Battery Park City|        East Chelsea|  2806| 33237.96000000004|  8351.69999999999|\n",
      "|       2011|           1|       Alphabet City|Stuy Town/Peter C...|   563| 3564.679999999997|490.52000000000027|\n",
      "|       2011|           1|       Midtown North|Upper West Side N...|  6337| 67950.27999999988| 14821.47000000006|\n",
      "|       2011|           1|       Midtown South|    Brooklyn Heights|   623|11622.549999999994|3421.1200000000013|\n",
      "|       2011|           1|      Manhattanville|        Bloomingdale|   255|           1948.01|375.11999999999983|\n",
      "|       2011|           1|Upper East Side N...|Williamsburg (Sou...|   136|           3340.83|            1079.5|\n",
      "|       2011|           1|   East Harlem North|         Murray Hill|   292| 4648.599999999998|1325.0999999999988|\n",
      "|       2011|           1|Prospect-Lefferts...|  DUMBO/Vinegar Hill|     4| 59.49999999999999|             15.03|\n",
      "|       2011|           1|       Alphabet City|Financial Distric...|   350|3915.6900000000032|1098.0300000000002|\n",
      "|       2011|           1|          Greenpoint|Prospect-Lefferts...|    21|            497.99|159.48000000000002|\n",
      "+-----------+------------+--------------------+--------------------+------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count, sum\n",
    "\n",
    "# Agrupa el DataFrame por cualquier columna (por ejemplo, \"col1\")\n",
    "# y realiza las agregaciones de conteo y suma\n",
    "agg_df = df.groupBy(\"pickup_year\",\"pickup_month\",\"PU_Zone\", \"DO_Zone\" ).agg(count(\"*\").alias(\"conteo\"), sum(\"total_amount\").alias(\"tot_amt\"), sum(\"trip_distance\").alias(\"distancia\"))\n",
    "\n",
    "#si quisiera redondear:\n",
    "#agg_df = agg_df.withColumn(\"tot_amt\", round(agg_df[\"tot_amt\"], 2))\n",
    "\n",
    "\n",
    "# Muestra el nuevo DataFrame\n",
    "agg_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(pickup_year,IntegerType,true),StructField(pickup_month,IntegerType,true),StructField(PU_Zone,StringType,true),StructField(DO_Zone,StringType,true),StructField(conteo,LongType,false),StructField(tot_amt,DoubleType,true),StructField(distancia,DoubleType,true)))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df.write.parquet('s3a://user-data/grupo-03/taxis-2011')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1596321158309973,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Notebook taxis",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
